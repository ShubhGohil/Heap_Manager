{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zhGiEOVfr3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import all necessary modules and packages\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D\n",
        "#import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy1g3vp_CfJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " %tensorflow_version 2.x\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7lAHWpCFLlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the mnist dataset in the variables from keras library\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0EqrtbuF5TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0],28,28,1) #reshape both training and test set into 4-dim array of shape (60000,28,28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
        "\n",
        "x_train = x_train.astype('float32') #convert each value of the set into 32 bit floating point value\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train/255 #normalize each vector to bring the scale between [0,1] \n",
        "x_test = x_test/255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmvlH1eoKbfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bulid a seqential model and attach different layers to the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1))) #used to extract features of the image\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #used to reduce the size of image\n",
        "model.add(Conv2D(64, kernel_size=(3,3), input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) # Flattening the 2D arrays for dense or fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2)) #used to disable some neurons\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRc7U6C7Ljgx",
        "colab_type": "code",
        "outputId": "83490726-d10d-4642-896a-cf52138bdc99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#used to compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.optimizer.lr = 0.0002 #setting learning rate to 0.0002\n",
        "#initializing the train values in the model\n",
        "\n",
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"weights/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=3)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlYO4GjeBOhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "8b856b84-5219-472a-a868-687a823d9f2b"
      },
      "source": [
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs = 15,\n",
        "          shuffle='True',\n",
        "          callbacks=[cp_callback],\n",
        "          validation_data=((x_test,y_test))\n",
        "         )\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0686 - val_accuracy: 0.9905\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0665 - val_accuracy: 0.9905\n",
            "Epoch 3/15\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 00003: saving model to weights/cp-0003.ckpt\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0611 - val_accuracy: 0.9907\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0601 - val_accuracy: 0.9909\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0647 - val_accuracy: 0.9902\n",
            "Epoch 6/15\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994\n",
            "Epoch 00006: saving model to weights/cp-0006.ckpt\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0616 - val_accuracy: 0.9911\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0618 - val_accuracy: 0.9915\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0636 - val_accuracy: 0.9909\n",
            "Epoch 9/15\n",
            "59552/60000 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 00009: saving model to weights/cp-0009.ckpt\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0738 - val_accuracy: 0.9902\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0716 - val_accuracy: 0.9903\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0717 - val_accuracy: 0.9902\n",
            "Epoch 12/15\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00012: saving model to weights/cp-0012.ckpt\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0690 - val_accuracy: 0.9913\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0668 - val_accuracy: 0.9910\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0627 - val_accuracy: 0.9907\n",
            "Epoch 15/15\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 00015: saving model to weights/cp-0015.ckpt\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0654 - val_accuracy: 0.9911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7fde1b99b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCmXg8_CBeRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzjXxOKLOKIH",
        "colab_type": "code",
        "outputId": "508b580d-fe4d-41aa-c91e-cdd69423097d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#evaluate the model on test set\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 84us/sample - loss: 0.0654 - accuracy: 0.9911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06536114775585147, 0.9911]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}